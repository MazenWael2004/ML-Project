{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525c2825ca42294b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T00:07:21.753040Z",
     "start_time": "2025-12-08T00:07:21.609909Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c89f0ca4d5f87a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T00:07:21.764817Z",
     "start_time": "2025-12-08T00:07:21.761056Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd()\n",
    "DATASET_PATH = BASE_DIR / 'dataset'\n",
    "CATEGORIES = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "TARGET_COUNT = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f20741073e417d6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T00:07:21.827572Z",
     "start_time": "2025-12-08T00:07:21.812018Z"
    }
   },
   "outputs": [],
   "source": [
    "def getImages(categoryPath):\n",
    "    return list(categoryPath.glob('*.jpg'))\n",
    "\n",
    "\n",
    "def printCategoryCounts():\n",
    "    print(\"\\nImage counts per category:\")\n",
    "    print(\"-\" * 30)\n",
    "    for categoryName in CATEGORIES:\n",
    "        categoryPath = DATASET_PATH / categoryName\n",
    "        imageCount = len(getImages(categoryPath))\n",
    "        print(f\"{categoryName:15s}: {imageCount} images\")\n",
    "\n",
    "\n",
    "def validateAndCleanDataset():\n",
    "    if not DATASET_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Dataset not found at: {DATASET_PATH}\")\n",
    "    print(\"Validating dataset for corrupted images...\")\n",
    "    categoryDirectories = [directory for directory in DATASET_PATH.iterdir() if directory.is_dir()]\n",
    "    print(f\"Found {len(categoryDirectories)} categories: {[category.name for category in categoryDirectories]}\\n\")\n",
    "    totalRemovedImages = 0\n",
    "    for categoryDirectory in sorted(categoryDirectories):\n",
    "        imageFiles = [file for file in categoryDirectory.iterdir() if file.is_file()]\n",
    "        removedCount = 0\n",
    "        for imagePath in imageFiles:\n",
    "            if cv2.imread(str(imagePath)) is None:\n",
    "                print(f\"Removing: {imagePath.name} as it is corrupted.\")\n",
    "                try:\n",
    "                    os.remove(imagePath)\n",
    "                    removedCount += 1\n",
    "                except Exception as error:\n",
    "                    print(f\"Warning: Could not remove: {error}\")\n",
    "        numberOfValidImages = len(imageFiles) - removedCount\n",
    "        print(f\"{categoryDirectory.name}: {numberOfValidImages}/{len(imageFiles)} valid images\")\n",
    "        totalRemovedImages += removedCount\n",
    "    print(f\"\\nValidation complete. Removed {totalRemovedImages} corrupted file(s).\")\n",
    "    printCategoryCounts()\n",
    "\n",
    "\n",
    "def augmentImage(image):\n",
    "    height, width = image.shape[:2]\n",
    "    center = (width / 2, height / 2)\n",
    "    augmentations = [\n",
    "        cv2.flip(image, 1),  # Horizontal flip\n",
    "        cv2.flip(image, 0),  # Vertical flip\n",
    "        cv2.warpAffine(image, cv2.getRotationMatrix2D(center, 90, 1.0), (width, height)), # 90 degrees\n",
    "        cv2.warpAffine(image, cv2.getRotationMatrix2D(center, 180, 1.0), (width, height)), # 180 degrees\n",
    "        cv2.warpAffine(image, cv2.getRotationMatrix2D(center, 270, 1.0), (width, height)), # 270 degrees\n",
    "        cv2.convertScaleAbs(image, alpha=1.3, beta=30),   # Brightness +30\n",
    "        cv2.convertScaleAbs(image, alpha=0.7, beta=-30),  # Brightness -30\n",
    "        cv2.GaussianBlur(image, (5, 5), 0),               # Gaussian blur 5x5\n",
    "    ]\n",
    "    # Zoom crop\n",
    "    scale = 1.2\n",
    "    newHeight, newWidth = int(height * scale), int(width * scale)\n",
    "    resized = cv2.resize(image, (newWidth, newHeight))\n",
    "    startHeight, startWidth = (newHeight - height) // 2, (newWidth - width) // 2\n",
    "    augmentations.append(resized[startHeight:startHeight + height, startWidth:startWidth + width])\n",
    "    return augmentations\n",
    "\n",
    "\n",
    "def augmentDataset():\n",
    "    print(f\"\\nAugmenting images to reach {TARGET_COUNT} per category...\")\n",
    "    for categoryName in CATEGORIES:\n",
    "        categoryPath = DATASET_PATH / categoryName\n",
    "        imagePaths = getImages(categoryPath)\n",
    "        currentImageCount = len(imagePaths)\n",
    "        imagesNeeded = TARGET_COUNT - currentImageCount\n",
    "        print(f\"\\n{categoryName}: {currentImageCount} images\", end=\"\")\n",
    "        if imagesNeeded <= 0:\n",
    "            print(\" - Already sufficient\")\n",
    "            continue\n",
    "        print(f\" (Need {imagesNeeded} more)\")\n",
    "        # Load original images using tqdm for progress\n",
    "        originalImages = [(cv2.imread(str(imageFile)), imageFile.stem) for imageFile in tqdm(imagePaths, desc=\"Loading\")]\n",
    "        originalImages = [(image, name) for image, name in originalImages]\n",
    "        # Generate augmented images\n",
    "        generatedCount = 0\n",
    "        while generatedCount < imagesNeeded:\n",
    "            image, imageName = random.choice(originalImages)\n",
    "            for augmentationIndex, augmentedImage in enumerate(augmentImage(image)):\n",
    "                if generatedCount >= imagesNeeded:\n",
    "                    break\n",
    "                savePath = categoryPath / f\"{imageName}_augmented_{generatedCount}_{augmentationIndex}.jpg\"\n",
    "                cv2.imwrite(str(savePath), augmentedImage)\n",
    "                generatedCount += 1\n",
    "        print(f\"Generated {generatedCount} augmented images\")\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Augmentation complete.\")\n",
    "    printCategoryCounts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b6232139b3f3d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T00:07:56.199153Z",
     "start_time": "2025-12-08T00:07:21.873890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataset for corrupted images...\n",
      "Found 6 categories: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
      "\n",
      "cardboard: 500/500 valid images\n",
      "glass: 500/500 valid images\n",
      "metal: 500/500 valid images\n",
      "paper: 500/500 valid images\n",
      "plastic: 500/500 valid images\n",
      "trash: 500/500 valid images\n",
      "\n",
      "Validation complete. Removed 0 corrupted file(s).\n",
      "\n",
      "Image counts per category:\n",
      "------------------------------\n",
      "cardboard      : 500 images\n",
      "glass          : 500 images\n",
      "metal          : 500 images\n",
      "paper          : 500 images\n",
      "plastic        : 500 images\n",
      "trash          : 500 images\n"
     ]
    }
   ],
   "source": [
    "validateAndCleanDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e71037173f1d61b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T00:08:02.095509Z",
     "start_time": "2025-12-08T00:07:56.296679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmenting images to reach 500 per category...\n",
      "\n",
      "cardboard: 500 images - Already sufficient\n",
      "\n",
      "glass: 500 images - Already sufficient\n",
      "\n",
      "metal: 500 images - Already sufficient\n",
      "\n",
      "paper: 500 images - Already sufficient\n",
      "\n",
      "plastic: 500 images - Already sufficient\n",
      "\n",
      "trash: 500 images - Already sufficient\n",
      "\n",
      "==================================================\n",
      "Augmentation complete.\n",
      "\n",
      "Image counts per category:\n",
      "------------------------------\n",
      "cardboard      : 500 images\n",
      "glass          : 500 images\n",
      "metal          : 500 images\n",
      "paper          : 500 images\n",
      "plastic        : 500 images\n",
      "trash          : 500 images\n"
     ]
    }
   ],
   "source": [
    "augmentDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f040739",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m image = cv2.resize(image,(\u001b[32m128\u001b[39m,\u001b[32m128\u001b[39m)) \n\u001b[32m     10\u001b[39m gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m hog_features, _ = \u001b[43mhog\u001b[49m(gray, pixels_per_cell=(\u001b[32m8\u001b[39m,\u001b[32m8\u001b[39m),\n\u001b[32m     12\u001b[39m                   cells_per_block=(\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m), visualize=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     13\u001b[39m hist = cv2.calcHist([image], [\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m, [\u001b[32m8\u001b[39m,\u001b[32m8\u001b[39m,\u001b[32m8\u001b[39m], [\u001b[32m0\u001b[39m,\u001b[32m256\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m256\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m256\u001b[39m])\n\u001b[32m     14\u001b[39m hist = cv2.normalize(hist, hist).flatten()\n",
      "\u001b[31mNameError\u001b[39m: name 'hog' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature Extraction Step\n",
    "ROWS = []\n",
    "y = []\n",
    "for category_dir in DATASET_PATH.iterdir(): # For each category directory\n",
    "    if category_dir.is_dir(): # Ensure it's a directory\n",
    "        category = category_dir.name # Get category name\n",
    "        for img in category_dir.iterdir(): # For each image in the category directory\n",
    "            image = cv2.imread(str(img)) # Read the image\n",
    "            image = cv2.resize(image,(128,128)) \n",
    "            gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            hog_features, _ = hog(gray, pixels_per_cell=(8,8),\n",
    "                              cells_per_block=(2,2), visualize=True)\n",
    "            hist = cv2.calcHist([image], [0,1,2], None, [8,8,8], [0,256,0,256,0,256])\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "            features = np.hstack([hog_features, hist])\n",
    "\n",
    "            ROWS.append(features)\n",
    "            y.append(category)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = np.array(ROWS)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a784598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to DataFrame\n",
    "df = pd.DataFrame(ROWS)\n",
    "\n",
    "# Add a label column\n",
    "df['label'] = y\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path): #for KNN\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "\n",
    "    hist = cv2.calcHist([img], [0,1,2], None, \n",
    "                         [8,8,8], [0,256,0,256,0,256])\n",
    "\n",
    "    return cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f29fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: c:\\Users\\AFAQE\\Documents\\GitHub\\ML-Project\\dataset\\cardboard\n",
      "Processing: c:\\Users\\AFAQE\\Documents\\GitHub\\ML-Project\\dataset\\glass\n",
      "Processing: c:\\Users\\AFAQE\\Documents\\GitHub\\ML-Project\\dataset\\metal\n",
      "Processing: c:\\Users\\AFAQE\\Documents\\GitHub\\ML-Project\\dataset\\paper\n",
      "Processing: c:\\Users\\AFAQE\\Documents\\GitHub\\ML-Project\\dataset\\plastic\n",
      "Processing: c:\\Users\\AFAQE\\Documents\\GitHub\\ML-Project\\dataset\\trash\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "DATASET_PATH = BASE_DIR / \"dataset\"\n",
    "\n",
    "CATEGORIES = [\"cardboard\", \"glass\", \"metal\", \"paper\", \"plastic\", \"trash\"]\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "label_map = {name: idx for idx, name in enumerate(CATEGORIES)}\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    folder = DATASET_PATH / category\n",
    "    print(\"Processing:\", folder)\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = folder / filename\n",
    "        features = extract_features(str(file_path))\n",
    "\n",
    "        if features is not None:\n",
    "            X.append(features)\n",
    "            y.append(label_map[category])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc32e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fa65aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_val = scaler.transform(X_val)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f3c1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"X_val.npy\", X_val)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"y_val.npy\", y_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MSI-Env)",
   "language": "python",
   "name": "msi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
